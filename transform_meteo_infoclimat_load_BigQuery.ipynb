{"cells": [{"cell_type": "markdown", "id": "a7e36dd7-c363-42b6-b5bb-1953f2454645", "metadata": {}, "source": "# Transformation des donn\u00e9es infoclimat"}, {"cell_type": "markdown", "id": "988c4de8-641d-4734-b226-0766c922fd25", "metadata": {}, "source": "**Auteur :**  Steve Caron  \n**Date de cr\u00e9ation :** 2023/08/23  \n**Pr\u00e9sentation :** Ce notebook transforme des donn\u00e9es stock\u00e9es dans un bucket GCP et les envoie vers BigQuery\n\n\n**Pr\u00e9requis :** \n- Un bucket gcp pour le stockage de donn\u00e9es. (BUCKET_NAME)\n- Une table BigQuerry contenant la liste des station du reseau infoclimat (TABLE_ID_INPUT)\n\n**Inputs :** \n\n**Params:**\n* NOM_BUCKET : nom du bucket GCP, doit \u00eatre dans le m\u00eame projet.\n* NOM_REPERTOIRE : Repertoire du Bucket dans lequel se trouvent les fichiers csv.\n* HEADER_CSV : Param\u00e8tre qui pr\u00e9cise si les fichiers CSV ont des header (oui = True, non=False)\n* ID_TABLE_INPUT : ID de la table BigQuery, doit \u00eatre dans le m\u00eame projet.\n* ID_TABLE_OUTPUT : ID de la table BigQuery, doit \u00eatre dans le m\u00eame projet.\n* NOM_BUCKET_TEMP : Nom du bucket temporaire pour l'\u00e9criture dans BigQuery.\n* MODE_ECRITURE : Mode d'\u00e9criture de la table BigQuery ( exemple : \"overwrite\", \"append\")"}, {"cell_type": "markdown", "id": "4c6bc7ba-c194-46b9-a0e6-715cc6c2d33b", "metadata": {}, "source": "# Import des librairies"}, {"cell_type": "code", "execution_count": 81, "id": "5533debb-7c9e-47fc-b4ac-e6870851426f", "metadata": {}, "outputs": [], "source": "from google.cloud import bigquery, storage\nimport os\nfrom pyspark.sql.functions import col,sum,avg,max,min,when,lower\nfrom pyspark.sql.types import StringType,DateType,FloatType,IntegerType,DecimalType"}, {"cell_type": "markdown", "id": "74a88162-01c2-49f0-93d7-fd00bb7d0c78", "metadata": {}, "source": "# Definition des Param\u00e8tres"}, {"cell_type": "code", "execution_count": 82, "id": "4b8d7b8f-e9e3-4759-bdd5-f1eae19dbbf6", "metadata": {}, "outputs": [], "source": "NOM_BUCKET = 'code_de_source_lake'\nNOM_REPERTOIRE = \"infoclimat\"\nHEADER_CSV = True\nID_TABLE_INPUT = \"code-de-source.donnees_code_de_source.stations_meteo\"\nID_TABLE_OUTPUT = \"code-de-source.donnees_code_de_source.donnees_meteo_test\"\nNOM_BUCKET_TEMP = \"traitement_meteo_temp\"\nMODE_ECRITURE = \"overwrite\""}, {"cell_type": "markdown", "id": "b8a17337-23fc-405e-a6ea-8c82fe82db3a", "metadata": {}, "source": "# Recup\u00e9ration des fichiers dans le Bucket"}, {"cell_type": "code", "execution_count": 83, "id": "0fbd112d-e1e8-4e23-a38a-32ccc82f6ba3", "metadata": {}, "outputs": [], "source": "# Initialisation de la liste de fichier\nnoms_fichier = []\n\n# Definition du delimiter\ndelimiter = None\n\n# Initialisation du client\nstorage_client = storage.Client()\n\n# Note: Client.list_blobs requires at least package version 1.17.0.\nblobs = storage_client.list_blobs(NOM_BUCKET, prefix=NOM_REPERTOIRE, delimiter=delimiter)\n\n# Parcourir les objets (fichiers) dans le bucket\nfor blob in blobs:\n    noms_fichier.append(\"gs://{}/{}\".format(NOM_BUCKET,blob.name))"}, {"cell_type": "markdown", "id": "806a1e1e-b271-47dc-8483-32ae80160ba3", "metadata": {}, "source": "# Lecture des fichier avec Spark"}, {"cell_type": "code", "execution_count": 84, "id": "b1f3bc0f-6ac8-4c2a-b84d-36ecb1d83b5c", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "donnees_brut = spark.read \\\n    .option(\"header\", HEADER_CSV) \\\n    .csv(noms_fichier)"}, {"cell_type": "markdown", "id": "e678d0cc-63bd-4468-ab66-b3310075c4a7", "metadata": {}, "source": "# Renommer les colonnes"}, {"cell_type": "code", "execution_count": 85, "id": "89152d30-5188-46ec-a762-39c6ae054852", "metadata": {}, "outputs": [], "source": "donnees_renommees = donnees_brut.withColumnRenamed(\"station_id\",\"code_station\")\\\n           .withColumnRenamed(\"dh_utc\",\"date\")\\\n           .withColumnRenamed(\"vent_moyen\",\"vitesse_du_vent\")\\\n           .withColumnRenamed(\"vent_direction\",\"direction_du_vent\")\\\n           .withColumnRenamed(\"pluie_3h\",\"precipitation_3h\")\\\n           .withColumnRenamed(\"pluie_1h\",\"precipitation_1h\")"}, {"cell_type": "code", "execution_count": 86, "id": "2e45d5ff-8c01-40ed-a14f-4c2d9b0e8162", "metadata": {}, "outputs": [], "source": "# donnees_renommees.printSchema()\n# print(type(donnees_renommees))"}, {"cell_type": "markdown", "id": "7d2af991-25b3-4ac9-8adb-97650479e876", "metadata": {}, "source": "# Nettoyage des lignes avec vitesses de vent mais pas de direction"}, {"cell_type": "markdown", "id": "9baff9d1-3dda-407a-81c0-7ab5c3931587", "metadata": {}, "source": "Dans certain cas, les stations mesures des vitesses de vent sans mesurer la direction du vent. Pouvant entrainer des vitesses de vent n\u00e9gative.  \nNous rempla\u00e7ons les enregistrement de vent sans direction par la valeur nulle."}, {"cell_type": "code", "execution_count": 87, "id": "22d7de9f-ca3a-4d8f-bcd6-5aab4f39f346", "metadata": {}, "outputs": [], "source": "donnees_nettoyees = donnees_renommees.withColumn(\"vitesse_du_vent\", \\\n        when((donnees_renommees[\"vitesse_du_vent\"].isNotNull()) & (donnees_renommees[\"direction_du_vent\"].isNull()), None)\\\n        .otherwise(donnees_renommees[\"vitesse_du_vent\"]))"}, {"cell_type": "markdown", "id": "ed76aa56-c0db-4f89-8a24-f8d13509603a", "metadata": {}, "source": "# Typage des colonnes"}, {"cell_type": "code", "execution_count": 88, "id": "a72b30cd-7e74-4c8a-bdf5-4c42155b5d5d", "metadata": {}, "outputs": [], "source": "donnees_typees = donnees_nettoyees.withColumn(\"date\",col(\"date\").cast(DateType()))\\\n    .withColumn(\"temperature\",col(\"temperature\").cast(DecimalType(10,1)))\\\n    .withColumn(\"pression\",col(\"pression\").cast(IntegerType()))\\\n    .withColumn(\"humidite\",col(\"humidite\").cast(IntegerType()))\\\n    .withColumn(\"point_de_rosee\",col(\"point_de_rosee\").cast(DecimalType(10,1)))\\\n    .withColumn(\"vitesse_du_vent\",col(\"vitesse_du_vent\").cast(DecimalType(10,2)))\\\n    .withColumn(\"vent_rafales\",col(\"vent_rafales\").cast(DecimalType(10,2)))\\\n    .withColumn(\"direction_du_vent\",col(\"direction_du_vent\").cast(IntegerType()))\\\n    .withColumn(\"precipitation_3h\",col(\"precipitation_3h\").cast(DecimalType(10,1)))\\\n    .withColumn(\"precipitation_1h\",col(\"precipitation_1h\").cast(DecimalType(10,1)))"}, {"cell_type": "code", "execution_count": 89, "id": "0e60e5b9-b501-480c-8859-27996a290838", "metadata": {}, "outputs": [], "source": "#  donnees_typees.printSchema()\n# donnees_typees.show(1)"}, {"cell_type": "markdown", "id": "00d4db7f-164e-454d-9190-eef9fd5b91bb", "metadata": {}, "source": "# Ajout d'une colone pour la temperature max, la temperature min, la pression max, la pression min, la vitesse du vent max"}, {"cell_type": "code", "execution_count": 90, "id": "c9f716fb-258f-42d4-aa3a-aa54dd62f9bd", "metadata": {}, "outputs": [], "source": "donnees_ajout_col = donnees_typees.withColumn(\"temperature_max\",col(\"temperature\"))\\\n.withColumn(\"temperature_min\",col(\"temperature\"))\\\n.withColumn(\"pression_max\",col(\"pression\"))\\\n.withColumn(\"pression_min\",col(\"pression\"))\\\n.withColumn(\"vitesse_du_vent_max\",col(\"vitesse_du_vent\"))"}, {"cell_type": "code", "execution_count": 91, "id": "7a6d928e-56fa-40ed-8daa-c698d62f4d39", "metadata": {}, "outputs": [], "source": "# donnees_ajout_col.printSchema()\n# print(type(donnees_ajout_col))"}, {"cell_type": "markdown", "id": "b6413b9b-33c6-4ffa-8c36-0a11755eec27", "metadata": {}, "source": "# Aggregation par date"}, {"cell_type": "markdown", "id": "d3bbef90-5e0c-444d-b2c7-90439b645dd9", "metadata": {}, "source": "Je fais une aggr\u00e9gation par date et par code station pour n'avoir qu'une seule mesure par jour, et non pas une mesure toutes les 20minutes ou une mesure par heure ..."}, {"cell_type": "code", "execution_count": 92, "id": "3e160773-5111-412d-913b-b50f546a2bea", "metadata": {}, "outputs": [], "source": "donnees_aggregees = donnees_ajout_col.groupBy(\"code_station\",\"date\") \\\n    .agg(avg(\"temperature\").cast(DecimalType(10,1)).alias(\"temperature\"), \\\n         min(\"temperature_min\").alias(\"temperature_min\"), \\\n         max(\"temperature_max\").alias(\"temperature_max\"), \\\n         avg(\"pression\").cast(IntegerType()).alias(\"pression\"),\\\n         min(\"pression_min\").cast(IntegerType()).alias(\"pression_min\"), \\\n         max(\"pression_max\").cast(IntegerType()).alias(\"pression_max\"), \\\n         avg(\"humidite\").cast(IntegerType()).alias(\"humidite\"),\\\n         avg(\"point_de_rosee\").cast(DecimalType(10,1)).alias(\"point_de_rosee\"),\\\n         avg(\"vitesse_du_vent\").cast(DecimalType(10,2)).alias(\"vitesse_du_vent\"),\\\n         max(\"vitesse_du_vent_max\").alias(\"vitesse_du_vent_max\"), \\\n         avg(\"direction_du_vent\").cast(IntegerType()).alias(\"direction_du_vent\"),\\\n         sum(\"precipitation_3h\").alias(\"precipitation\")) \\\n        .orderBy(\"date\")"}, {"cell_type": "code", "execution_count": 93, "id": "684af928-7d95-47d8-acb9-f8fc7147f4bf", "metadata": {}, "outputs": [], "source": "# donnees_aggregees.show(5)\n# print(type(donnees_aggregees))"}, {"cell_type": "markdown", "id": "218e2b76-3aae-4b57-85c1-cbf948fa9978", "metadata": {}, "source": "# Collecte des informations sur les stations"}, {"cell_type": "markdown", "id": "0eeb0bf7-7205-44f1-8ad2-b6219d2b0d51", "metadata": {}, "source": "Il faut ajouter \u00e0 ma table les informations sur les stations climatique. Ces informations \u00e9tant contenues dans une autre table, je charge cette table pour ensuite faire une jointure des deux tables."}, {"cell_type": "code", "execution_count": 94, "id": "550a1227-c631-4171-92e2-4ed636d4d475", "metadata": {}, "outputs": [], "source": "stations = spark.read.format('bigquery') \\\n  .option('table', ID_TABLE_INPUT) \\\n  .load()\n\n#Je selectionne uniquement les colonnes que je veux garder.\nstations = stations.select(\"code_station\", \"nom_station\", \"coordonnees_x\", \"coordonnees_y\")"}, {"cell_type": "code", "execution_count": 95, "id": "50f9dbe0-5374-40e1-906b-495abf9e5540", "metadata": {}, "outputs": [], "source": "# stations.printSchema()\n# stations.show(5)\n# print(type(stations))"}, {"cell_type": "markdown", "id": "f9cd495d-c19e-4a5e-a0ef-ed7c86ddcd2b", "metadata": {}, "source": "# Jointure des tables"}, {"cell_type": "code", "execution_count": 96, "id": "b58d0004-6f76-4cc7-8cb6-b5ee92146ed7", "metadata": {}, "outputs": [], "source": "data_jointes = donnees_aggregees.join(stations,\n                                      donnees_aggregees[\"code_station\"] == stations[\"code_station\"]\n                                     ).drop(stations[0])"}, {"cell_type": "code", "execution_count": 97, "id": "1964a380-9968-4571-92a0-ee25e7cf3a6d", "metadata": {}, "outputs": [], "source": "# data_jointes.printSchema()"}, {"cell_type": "markdown", "id": "7ae7f04d-661b-413a-9127-8b1387aeb85f", "metadata": {}, "source": "# Renommer les nouvelles colonnes"}, {"cell_type": "code", "execution_count": 98, "id": "3405016b-08b9-4e41-b535-956d9d5c417b", "metadata": {}, "outputs": [], "source": "data_jointes_renommees = data_jointes.withColumnRenamed(\"coordonnees_x\",\"longitude_x\")\\\n                                     .withColumnRenamed(\"coordonnees_y\",\"latitude_y\")\\\n                                     .withColumnRenamed(\"nom_station\",\"localite\")"}, {"cell_type": "code", "execution_count": 99, "id": "9d8eef85-8dcc-4e4c-8747-cb6e23078f31", "metadata": {}, "outputs": [], "source": "# data_jointes_renommees.printSchema()"}, {"cell_type": "markdown", "id": "e192558c-89de-409f-a3e3-a03ce52cf2ca", "metadata": {}, "source": "# Typage des nouvelles colonnes"}, {"cell_type": "code", "execution_count": 100, "id": "0b4b8660-34ac-4f4c-9cdb-f454e7ba651d", "metadata": {}, "outputs": [], "source": "data_jointes_typees = data_jointes_renommees.select(\"date\",\"localite\",\\\n                                   \"longitude_x\",\"latitude_y\",\\\n                                   \"temperature\",\"temperature_min\",\"temperature_max\",\\\n                                   \"pression\",\"pression_min\",\"pression_max\",\\\n                                   \"humidite\",\"point_de_rosee\",\\\n                                   \"vitesse_du_vent\",\"vitesse_du_vent_max\",\"direction_du_vent\",\\\n                                   \"precipitation\")\\\n                                    .withColumn(\"precipitation\",col(\"precipitation\").cast(DecimalType(10,1)))\\\n                                    .withColumn(\"humidite\",col(\"humidite\").cast(DecimalType(10,1)))\\\n                                    .withColumn(\"vitesse_du_vent\",col(\"vitesse_du_vent\").cast(DecimalType(10,1)))\\\n                                    .withColumn(\"vitesse_du_vent_max\",col(\"vitesse_du_vent_max\").cast(DecimalType(10,1)))\\\n                                    .withColumn(\"longitude_x\",col(\"longitude_x\").cast(StringType()))\\\n                                    .withColumn(\"latitude_y\",col(\"latitude_y\").cast(StringType()))\\\n                                    .withColumn(\"localite\",lower(col(\"localite\")))\n"}, {"cell_type": "code", "execution_count": 101, "id": "84e5f8b1-b011-461e-9ca3-e85ae3908866", "metadata": {}, "outputs": [], "source": "# data_jointes_typees.printSchema()\n# data_jointes_typees.show(1)"}, {"cell_type": "markdown", "id": "e6dc22d7-2998-4331-8a56-dd7d85c4e593", "metadata": {}, "source": "# Enregistrement dans une Table"}, {"cell_type": "code", "execution_count": 102, "id": "11165033-a754-403c-9180-23eb0ed40e11", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "Les donn\u00e9es sont enregistr\u00e9es dans la table code-de-source.donnees_code_de_source.donnees_meteo_test\n"}], "source": "data_jointes_typees.write \\\n  .format(\"bigquery\") \\\n  .option(\"table\",ID_TABLE_OUTPUT)\\\n  .option(\"temporaryGcsBucket\",NOM_BUCKET_TEMP) \\\n  .mode(MODE_ECRITURE) \\\n  .save()\n\nprint(f\"Les donn\u00e9es sont enregistr\u00e9es dans la table {ID_TABLE_OUTPUT}\")"}], "metadata": {"kernelspec": {"display_name": "PySpark", "language": "python", "name": "pyspark"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.10.8"}}, "nbformat": 4, "nbformat_minor": 5}